{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import egg.core as core\n",
    "\n",
    "import random\n",
    "\n",
    "from typing import Any, List, Optional, Sequence, Union\n",
    "\n",
    "import torch.utils.data\n",
    "from torch_geometric.data import Batch, Dataset, Data\n",
    "from torch_geometric.data.data import BaseData\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.data.datapipes import DatasetAdapter\n",
    "from torch_geometric.data.on_disk_dataset import OnDiskDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\"\"\"\n",
    "Set the options here. I used max_len=1 for now to have a better view when printing the messages. Otherwise they become very long.\n",
    "game_size doesn't matter for this set-up, I use it in the other graph game.\n",
    "For better readablity, I set the embedding size to 10 (this influences training of course).\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class Options:\n",
    "    # Agents\n",
    "    embedding_size: int = 10 # Default: 50\n",
    "    hidden_size: int = 20 # Default: 20\n",
    "    sender_cell: str = 'rnn' # 'rnn', 'gru', 'lstm'\n",
    "    max_len: int = 1 # Default: 1\n",
    "    gs_tau: int = 1.0 # Default: 1.0\n",
    "\n",
    "    # Training\n",
    "    n_epochs: int = 10\n",
    "    game_size: int = 20 # Default: 4\n",
    "    vocab_size: int = 100 # Default: 100\n",
    "    batch_size: int = 1 # Default: 16\n",
    "    training_mode: str = 'gs'  # 'rf' for Reinforce or 'gs' for Gumbel-Softmax\n",
    "\n",
    "opts = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FamilyMember:\n",
    "    \"\"\"\n",
    "    Represents a family member with gender, age, spouse, and children.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gender, age):\n",
    "        self.gender = gender\n",
    "        self.age = age\n",
    "        self.spouse = None\n",
    "        self.children = []\n",
    "\n",
    "    def create_spouse(self):\n",
    "        \"\"\"\n",
    "        Creates a spouse for the family member based on their gender and age.\n",
    "        Returns the created spouse.\n",
    "        \"\"\"\n",
    "        spouse_gender = 'f' if self.gender == 'm' else 'm'\n",
    "        spouse_age = random.randint(max(18, self.age - 5), min(self.age + 5, 100))\n",
    "        spouse = FamilyMember(spouse_gender, spouse_age)\n",
    "        self.spouse = spouse\n",
    "        spouse.spouse = self\n",
    "        return spouse\n",
    "\n",
    "    def create_children(self, max_children=4):\n",
    "        \"\"\"\n",
    "        Creates children for the family member and their spouse.\n",
    "        The number of children is randomly determined.\n",
    "        \"\"\"\n",
    "        children_count = 2 #random.randint(1, max_children) # Change this to adjust the size of the graph.\n",
    "        youngest_parent_age = min(self.age, self.spouse.age)\n",
    "        for _ in range(children_count):\n",
    "            child_gender = random.choice(['m', 'f'])\n",
    "            max_child_age = max(0, youngest_parent_age - 20)\n",
    "            min_child_age = max(0, youngest_parent_age - 30)\n",
    "            child_age = random.randint(min_child_age, max_child_age)\n",
    "            child = FamilyMember(child_gender, child_age)\n",
    "            self.children.append(child)\n",
    "            self.spouse.children.append(child)\n",
    "\n",
    "def create_family_tree(generations):\n",
    "    age_range = (80,100)\n",
    "    root_age = random.randint(*age_range)\n",
    "    root_member = FamilyMember('m', root_age)\n",
    "\n",
    "    spouse = root_member.create_spouse()\n",
    "    current_generation = [(root_member, spouse)]\n",
    "    \n",
    "    all_members = {0: root_member, 1: spouse}\n",
    "    next_index = 2  # Start indexing from 2 as 0 and 1 are already used\n",
    "\n",
    "    for gen in range(1, generations):\n",
    "        next_generation = []\n",
    "        for parent1, parent2 in current_generation:\n",
    "            parent1.create_children()\n",
    "            for child in parent1.children:\n",
    "                all_members[next_index] = child\n",
    "                next_index += 1\n",
    "                if gen < generations - 1:\n",
    "                    spouse = child.create_spouse()\n",
    "                    all_members[next_index] = spouse\n",
    "                    next_generation.append((child, spouse))\n",
    "                    next_index += 1\n",
    "        current_generation = next_generation\n",
    "\n",
    "    return all_members\n",
    "\n",
    "def create_data_object(all_members):\n",
    "    # Convert genders to a binary representation and collect node features\n",
    "    gender_to_binary = {'m': 0, 'f': 1}\n",
    "    x = [[gender_to_binary[member.gender], member.age] for index, member in all_members.items()]\n",
    "\n",
    "    # Prepare edge_index and edge_attr\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "\n",
    "    for index, member in all_members.items():\n",
    "        if member.spouse:\n",
    "            spouse_index = list(all_members.keys())[list(all_members.values()).index(member.spouse)]\n",
    "            # Add edges for spouses in both directions with the 'married' attribute\n",
    "            edge_index.append([index, spouse_index])\n",
    "            edge_index.append([spouse_index, index])\n",
    "            edge_attr.extend([0, 0])  # 0 for 'married'\n",
    "\n",
    "        for child in member.children:\n",
    "            child_index = list(all_members.keys())[list(all_members.values()).index(child)]\n",
    "            # Add edges from children to this member with the 'childOf' attribute\n",
    "            edge_index.append([child_index, index])\n",
    "            edge_attr.append(1)  # 1 for 'childOf'\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.long)\n",
    "\n",
    "    # Create the data object\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class FamilyGraphDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for generating family graph data.\n",
    "\n",
    "    Args:\n",
    "        root (str): Root directory path.\n",
    "        number_of_graphs (int): Number of graphs to generate.\n",
    "        generations (int): Number of generations in each family tree.\n",
    "\n",
    "    Returns:\n",
    "        Data(x=[8, 2], edge_index=[2, 20], edge_attr=[20], labels=[8])\n",
    "    \"\"\"\n",
    "    def __init__(self, root, number_of_graphs, generations, transform=None, pre_transform=None):\n",
    "        self.number_of_graphs = number_of_graphs\n",
    "        self.generations = generations\n",
    "        super(FamilyGraphDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data = None\n",
    "        self.process()\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['family_graphs.pt']\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def generate_labels(self, num_nodes):\n",
    "        target_node_idx = random.randint(0, num_nodes - 1)\n",
    "        return target_node_idx\n",
    "    \n",
    "    def process(self):\n",
    "        if not os.path.isfile(self.processed_paths[0]):\n",
    "            self.data = []\n",
    "            for _ in range(self.number_of_graphs):\n",
    "                family_tree = create_family_tree(self.generations)\n",
    "                graph_data = create_data_object(family_tree)\n",
    "\n",
    "                # Generate random labels for each node\n",
    "                target_node_idx = self.generate_labels(graph_data.num_nodes)\n",
    "\n",
    "                # Store the labels as an attribute of the graph_data\n",
    "                graph_data.target_node_idx = target_node_idx\n",
    "\n",
    "                self.data.append(graph_data)\n",
    "\n",
    "            torch.save(self.data, self.processed_paths[0])\n",
    "        else:\n",
    "            self.data = torch.load(self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set the number of graphs and generations here. In the FamilyMember class you can set the number of children. For now, to make graphs of 4 nodes the number of children is 2 and generations is 2. Meaning two parents and two children = 4.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4, 2], edge_index=[2, 8], edge_attr=[8], target_node_idx=0)\n"
     ]
    }
   ],
   "source": [
    "dataset = FamilyGraphDataset(root='.../data', number_of_graphs=100, generations=2)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of nodes: 4.0\n"
     ]
    }
   ],
   "source": [
    "total_nodes = 0\n",
    "for i in range(0, len(dataset)):\n",
    "    total_nodes += dataset[i].x.shape[0]  # shape[0] gives the number of nodes in each graph\n",
    "\n",
    "average_nodes = total_nodes / len(dataset)\n",
    "print(\"Average number of nodes:\", average_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Here are the agents. I realised later that I did the embedding layers seperatley for each agent. Meaning the sender embeds the graph, then the receiver embeds the graph on its own. This could possibly lead to the receiver having very different embedding of the graph and thus having more difficuly understanding the message and finding the target node. So now the GAT layer is outside the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, embedding_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv(num_node_features, embedding_size, edge_dim=1, heads=2, concat=True)\n",
    "        self.conv2 = GATv2Conv(-1, embedding_size, edge_dim=1, heads=2, concat=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        h, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        h = self.conv1(x=h, edge_index=edge_index, edge_attr=edge_attr)     \n",
    "        h = F.relu(h)\n",
    "\n",
    "        h = self.conv2(x=h, edge_index=edge_index, edge_attr=edge_attr)     \n",
    "        h = F.relu(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sender(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, temperature):\n",
    "        super(Sender, self).__init__()\n",
    "        self.temp = temperature\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.gat = GAT(2, embedding_size) # 2 is num_node features, a little ugly to do it like this but it doesn't change \n",
    "        self.fc = nn.Linear((embedding_size * 2), hidden_size) # because I use 2 heads and concatenate them, embedding_size * 2\n",
    "\n",
    "    def forward(self, x, _aux_input):\n",
    "        data = _aux_input\n",
    "\n",
    "        target_node_idx = data.target_node_idx\n",
    "\n",
    "        h = self.gat(data)\n",
    "\n",
    "        target_embedding = h[target_node_idx]           \n",
    "\n",
    "        output = self.fc(target_embedding)                           \n",
    "\n",
    "        return output.view(-1, self.hidden_size)\n",
    "\n",
    "class Receiver(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size):\n",
    "        super(Receiver, self).__init__()\n",
    "\n",
    "        self.gat = GAT(2, embedding_size)\n",
    "        self.fc = nn.Linear(hidden_size, (embedding_size * 2))\n",
    "\n",
    "    def forward(self, message, _input, _aux_input):\n",
    "        data = _aux_input\n",
    "\n",
    "        h = self.gat(data)   \n",
    "\n",
    "        message_embedding = self.fc(message)                 \n",
    "\n",
    "        dot_products = torch.matmul(h, message_embedding.t()).t()   \n",
    "\n",
    "        probabilities = F.log_softmax(dot_products, dim=1)                      \n",
    "\n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouput for a single graph\n",
    "\n",
    "You can see the graph and its corresponding target node below, indexing starts at 0, so if the target node is 0 it takes the 1st node of the graph. The range is set in the dataset building function above:\n",
    "`target_node_idx = random.randint(0, num_nodes - 1)`. The graph is passed to both the sender and receiver, with the receiver also getting the sender message of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4, 2], edge_index=[2, 8], edge_attr=[8], target_node_idx=0)\n",
      "Sender's message: tensor([[ 4.9285,  0.3794,  0.9473,  2.3869, -0.5996,  4.6859,  3.9219,  3.5665,\n",
      "         -4.3103,  0.3931, -1.7749,  5.4911,  7.6793, -5.1749,  4.6028, -3.2139,\n",
      "         10.2020, -5.5374, -2.0164, -8.2498]], grad_fn=<ViewBackward0>)\n",
      "Sender's shape:  torch.Size([1, 20])\n",
      "Receiver's output: tensor([[-4.7771e+01, -4.7566e+01, -2.0946e-03, -6.1694e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Receiver's shape:  torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "sender = Sender(embedding_size=opts.embedding_size, hidden_size=opts.hidden_size, temperature=opts.gs_tau) \n",
    "receiver = Receiver(embedding_size=opts.embedding_size, hidden_size=opts.hidden_size) \n",
    "\n",
    "graph = dataset[0]\n",
    "print(graph)\n",
    "\n",
    "# Sender produces a message\n",
    "sender_output = sender(None, graph)\n",
    "print(\"Sender's message:\", sender_output)\n",
    "print(\"Sender's shape: \", sender_output.shape) # (n graphs, hidden size)\n",
    "\n",
    "# Receiver tries to identify the target node\n",
    "receiver_output = receiver(sender_output, None, graph)\n",
    "print(\"Receiver's output:\", receiver_output) # returns log probs for each node\n",
    "print(\"Receiver's shape: \", receiver_output.shape) # (n graphs, n nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following is for printing the embeddings without having to cope with it printing every epoch later.\n",
    "\"\"\"\n",
    "\n",
    "class SenderPrint(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, temperature):\n",
    "        super(SenderPrint, self).__init__()\n",
    "        self.temp = temperature\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.gcn = GAT(2, embedding_size) # 2 is num_node features, a little ugly to do it like this but it doesn't change \n",
    "        self.fc = nn.Linear((embedding_size * 2), hidden_size) # because I use 2 heads and concatenate them, embedding_size * 2\n",
    "\n",
    "    def forward(self, x, _aux_input):\n",
    "        data = _aux_input\n",
    "\n",
    "        target_node_idx = data.target_node_idx\n",
    "\n",
    "        h = self.gcn(data)\n",
    "\n",
    "        target_embedding = h[target_node_idx]           \n",
    "\n",
    "        output = self.fc(target_embedding)                           \n",
    "\n",
    "        return output.view(-1, self.hidden_size), h, target_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  Data(x=[4, 2], edge_index=[2, 8], edge_attr=[8], target_node_idx=0)\n",
      "h: tensor([[23.4326,  0.0000,  0.0000,  0.0000, 36.9734,  1.6236,  0.0000,  6.3429,\n",
      "          0.0000,  8.4839, 13.2722,  0.0000, 36.4619,  0.0000,  4.6447, 20.2840,\n",
      "         25.0810,  1.2073,  0.0000,  8.3897],\n",
      "        [23.4102,  0.0000,  0.0000,  0.0000, 36.9806,  1.6271,  0.0000,  6.2997,\n",
      "          0.0000,  8.5159, 13.2796,  0.0000, 36.4762,  0.0000,  4.6396, 20.2842,\n",
      "         25.0921,  1.2070,  0.0000,  8.3960],\n",
      "        [19.2740,  0.0000,  0.0000,  0.0000, 30.0949,  3.3817,  0.0000,  5.4792,\n",
      "          0.0000,  7.7906, 11.4679,  0.0000, 33.1418,  0.0000,  4.5721, 18.7955,\n",
      "         23.6619,  0.7205,  0.0000,  8.3582],\n",
      "        [20.4764,  0.0000,  0.0000,  0.0000, 31.9581,  3.5842,  0.0000,  5.8217,\n",
      "          0.0000,  8.2490, 12.1901,  0.0000, 35.2062,  0.0000,  4.8491, 19.9479,\n",
      "         25.1093,  0.7920,  0.0000,  8.8734]], grad_fn=<ReluBackward0>)\n",
      "target_embedding: tensor([23.4326,  0.0000,  0.0000,  0.0000, 36.9734,  1.6236,  0.0000,  6.3429,\n",
      "         0.0000,  8.4839, 13.2722,  0.0000, 36.4619,  0.0000,  4.6447, 20.2840,\n",
      "        25.0810,  1.2073,  0.0000,  8.3897], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sender_print = SenderPrint(embedding_size=opts.embedding_size, hidden_size=opts.hidden_size, temperature=opts.gs_tau)\n",
    "\n",
    "sender_output, h, target_emb = sender_print(None, graph)\n",
    "\n",
    "print(\"Input: \", graph)\n",
    "print(\"h:\", h)\n",
    "print(\"target_embedding:\", target_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the embedding h is size (nodes x embedding size). The input is printed above, you can check if the target embedding taken to the linear function is indeed the right index from the entire embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender's shape: torch.Size([1, 2, 100])\n",
      "Receiver's shape: torch.Size([1, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "sender_gs = core.RnnSenderGS(sender, opts.vocab_size, opts.embedding_size, opts.hidden_size, max_len=opts.max_len, temperature=opts.gs_tau, cell=opts.sender_cell)\n",
    "receiver_gs = core.RnnReceiverGS(receiver, opts.vocab_size, opts.embedding_size, opts.hidden_size, cell=opts.sender_cell)\n",
    "\n",
    "# Sender produces a message\n",
    "sender_output = sender_gs(None, graph)\n",
    "# print(\"Sender's message:\", sender_output)\n",
    "print(\"Sender's shape:\", sender_output.shape) # (n graphs, max_len+1, vocab size)\n",
    "\n",
    "# Receiver tries to identify the target node\n",
    "receiver_output = receiver_gs(sender_output, None, graph)\n",
    "# print(\"Receiver's output:\", receiver_output)\n",
    "print(\"Receiver's shape:\", receiver_output.shape) # (n graphs, max_len+1, n nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4, 2], edge_index=[2, 8], edge_attr=[8], target_node_idx=0)\n",
      "0\n",
      "0\n",
      "tensor(1.1499, grad_fn=<MeanBackward0>)\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "print(graph)\n",
    "\n",
    "def loss_nll(\n",
    "    _sender_input, _message, _receiver_input, receiver_output, labels, _aux_input):\n",
    "    \"\"\"\n",
    "    NLL loss - differentiable and can be used with both GS and Reinforce\n",
    "    \"\"\"\n",
    "    print(labels)\n",
    "    labels = torch.tensor([labels]).long()\n",
    "    nll = F.nll_loss(receiver_output, labels, reduction=\"none\")\n",
    "    acc = (labels == receiver_output.argmax(dim=1)).float().mean()\n",
    "    return nll, {\"acc\": acc}\n",
    "\n",
    "game = core.SenderReceiverRnnGS(sender_gs, receiver_gs, loss_nll)\n",
    "\n",
    "loss, interaction = game(sender_input=None, labels=graph.target_node_idx, receiver_input=None, aux_input=graph)\n",
    "print(loss)\n",
    "print(\"====================================\")\n",
    "# print(interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was an overview of the output for a single graph. Because the labels are in the same object as the graph data they never get mixed up (I believe). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching\n",
    "\n",
    "The following is when batching the graphs. Like I explained I need a size of 1 because otherwise indexing gets messed up. I will try to explain what happens in that case later. For now we use a size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a modified version of your dataloader.\n",
    "\"\"\"\n",
    "\n",
    "class Collater:\n",
    "    def __init__(\n",
    "        self,\n",
    "        game_size: int,  # the number of graphs for a game\n",
    "        dataset: Union[Dataset, Sequence[BaseData], DatasetAdapter],\n",
    "        follow_batch: Optional[List[str]] = None,\n",
    "        exclude_keys: Optional[List[str]] = None,\n",
    "    ):\n",
    "        self.game_size = game_size\n",
    "        self.dataset = dataset\n",
    "        self.follow_batch = follow_batch\n",
    "        self.exclude_keys = exclude_keys\n",
    "\n",
    "    def __call__(self, batch: List[Any]) -> Any:\n",
    "        elem = batch[0]\n",
    "        if isinstance(elem, BaseData):\n",
    "            batch = batch[:((len(batch) // self.game_size) * self.game_size)]  # we throw away the last batch_size % game_size\n",
    "            batch = Batch.from_data_list(\n",
    "                batch,\n",
    "                follow_batch=self.follow_batch,\n",
    "                exclude_keys=self.exclude_keys,\n",
    "            )\n",
    "            # we return a tuple (sender_input, labels, receiver_input, aux_input)\n",
    "            # we use aux_input to store minibatch of graphs\n",
    "            return (\n",
    "                torch.zeros(len(batch) // self.game_size, 1),  # we don't need sender_input --> create a fake one\n",
    "                batch.target_node_idx,  # the target is aways the first graph among game_size graphs\n",
    "                None,  # we don't care about receiver_input\n",
    "                batch  # this is a compact data for batch_size graphs \n",
    "            )\n",
    "\n",
    "        raise TypeError(f\"DataLoader found invalid type: '{type(elem)}'\")\n",
    "\n",
    "    def collate_fn(self, batch: List[Any]) -> Any:\n",
    "        if isinstance(self.dataset, OnDiskDataset):\n",
    "            return self(self.dataset.multi_get(batch))\n",
    "        return self(batch)\n",
    "\n",
    "\n",
    "class DataLoader(torch.utils.data.DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        game_size: int,  # the number of graphs for a game\n",
    "        dataset: Union[Dataset, Sequence[BaseData], DatasetAdapter],\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        follow_batch: Optional[List[str]] = None,\n",
    "        exclude_keys: Optional[List[str]] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.game_size = game_size\n",
    "        # Remove for PyTorch Lightning:\n",
    "        kwargs.pop('collate_fn', None)\n",
    "\n",
    "        # Save for PyTorch Lightning < 1.6:\n",
    "        self.follow_batch = follow_batch\n",
    "        self.exclude_keys = exclude_keys\n",
    "\n",
    "        self.collator = Collater(game_size, dataset, follow_batch, exclude_keys)\n",
    "\n",
    "        if isinstance(dataset, OnDiskDataset):\n",
    "            dataset = range(len(dataset))\n",
    "\n",
    "        super().__init__(\n",
    "            dataset,\n",
    "            batch_size,\n",
    "            shuffle,\n",
    "            collate_fn=self.collator.collate_fn,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 80\n",
      "Validation set length: 20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the lengths of the training and validation sets\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "game_size = 1 because we don't need distractor graphs. The nodes are distractors.\n",
    "\"\"\"\n",
    "\n",
    "train_loader = DataLoader(game_size=1, dataset=train_data, batch_size=opts.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(game_size=1, dataset=val_data, batch_size=opts.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs for batch\n",
    "\n",
    "The batch contains some irrelevant data. The second element is the label (or target node), this time returned as tensor. If it were a batch of more graphs it could look like this: tensor([3, 1, 2, 2]) for example. Meaning 4 graphs in the batch, each element defining the target node in an individual graph. The final element is the input data for the sender and receiver classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.]]), tensor([1]), None, DataBatch(x=[4, 2], edge_index=[2, 8], edge_attr=[8], target_node_idx=[1], batch=[4], ptr=[2]))\n",
      "====================================\n",
      "tensor([[0.]])\n",
      "tensor([1])\n",
      "None\n",
      "DataBatch(x=[4, 2], edge_index=[2, 8], edge_attr=[8], target_node_idx=[1], batch=[4], ptr=[2])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch)\n",
    "print(\"====================================\")\n",
    "print(*batch, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender's shape:  torch.Size([1, 20])\n",
      "Receiver's shape:  torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Sender produces a message\n",
    "sender_output = sender(None, batch[3])\n",
    "#print(\"Sender's message:\", sender_output)\n",
    "print(\"Sender's shape: \", sender_output.shape)\n",
    "\n",
    "# Receiver tries to identify the target node\n",
    "receiver_output = receiver(sender_output, None, batch[3])\n",
    "#print(\"Receiver's output:\", receiver_output)\n",
    "print(\"Receiver's shape: \", receiver_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender's shape: torch.Size([1, 2, 100])\n",
      "Receiver's output shape: torch.Size([1, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Sender produces a message\n",
    "sender_output = sender_gs(None, batch[3])\n",
    "#print(\"Sender's message:\", sender_output)\n",
    "print(\"Sender's shape:\", sender_output.shape) # batch size x max_len+1 x vocab size\n",
    "\n",
    "# Receiver tries to identify the target node\n",
    "receiver_output = receiver_gs(sender_output, None, batch[3])\n",
    "#print(\"Receiver's output:\", receiver_output)\n",
    "print(\"Receiver's output shape:\", receiver_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output dimensions are same as when we used a single graph of course, since we have 1 graph in the batch. If you were to increase batch size the dimensions would change from 1 to 4 for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1475, grad_fn=<MeanBackward0>)\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "def loss_nll(\n",
    "    _sender_input, _message, _receiver_input, receiver_output, labels, _aux_input):\n",
    "    \"\"\"\n",
    "    NLL loss - differentiable and can be used with both GS and Reinforce\n",
    "    \"\"\"\n",
    "    nll = F.nll_loss(receiver_output, labels, reduction=\"none\")\n",
    "    acc = (labels == receiver_output.argmax(dim=1)).float().mean()\n",
    "    return nll, {\"acc\": acc}\n",
    "\n",
    "game = core.SenderReceiverRnnGS(sender_gs, receiver_gs, loss_nll)\n",
    "\n",
    "loss, interaction = game(*batch)\n",
    "print(loss)\n",
    "print(\"====================================\")\n",
    "#print(interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 1.4233074188232422, \"acc\": 0.2751663327217102, \"length\": 1.9960514307022095, \"mode\": \"train\", \"epoch\": 1}\n",
      "{\"loss\": 1.4135353565216064, \"acc\": 0.30000001192092896, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 1}\n",
      "{\"loss\": 1.4137192964553833, \"acc\": 0.26232555508613586, \"length\": 1.9924099445343018, \"mode\": \"train\", \"epoch\": 2}\n",
      "{\"loss\": 1.386225938796997, \"acc\": 0.3499999940395355, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 2}\n",
      "{\"loss\": 1.3950414657592773, \"acc\": 0.20050778985023499, \"length\": 1.9913307428359985, \"mode\": \"train\", \"epoch\": 3}\n",
      "{\"loss\": 1.3741767406463623, \"acc\": 0.44999998807907104, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 3}\n",
      "{\"loss\": 1.3842742443084717, \"acc\": 0.29994508624076843, \"length\": 1.9954662322998047, \"mode\": \"train\", \"epoch\": 4}\n",
      "{\"loss\": 1.3663982152938843, \"acc\": 0.4000000059604645, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 4}\n",
      "{\"loss\": 1.3679454326629639, \"acc\": 0.2534807324409485, \"length\": 1.9879167079925537, \"mode\": \"train\", \"epoch\": 5}\n",
      "{\"loss\": 1.2370922565460205, \"acc\": 0.6000000238418579, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 5}\n",
      "{\"loss\": 1.0777615308761597, \"acc\": 0.37563639879226685, \"length\": 1.9940391778945923, \"mode\": \"train\", \"epoch\": 6}\n",
      "{\"loss\": 0.6980236172676086, \"acc\": 0.6000000238418579, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 6}\n",
      "{\"loss\": 0.7347893118858337, \"acc\": 0.5372450351715088, \"length\": 1.998440146446228, \"mode\": \"train\", \"epoch\": 7}\n",
      "{\"loss\": 0.680673360824585, \"acc\": 0.6000000238418579, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 7}\n",
      "{\"loss\": 0.7172516584396362, \"acc\": 0.5496518611907959, \"length\": 1.997901201248169, \"mode\": \"train\", \"epoch\": 8}\n",
      "{\"loss\": 0.6768578886985779, \"acc\": 0.6000000238418579, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 8}\n",
      "{\"loss\": 0.7029260396957397, \"acc\": 0.5371488332748413, \"length\": 1.9991028308868408, \"mode\": \"train\", \"epoch\": 9}\n",
      "{\"loss\": 0.6760973334312439, \"acc\": 0.6000000238418579, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 9}\n",
      "{\"loss\": 0.6880583763122559, \"acc\": 0.5374100804328918, \"length\": 1.999571442604065, \"mode\": \"train\", \"epoch\": 10}\n",
      "{\"loss\": 0.6771149635314941, \"acc\": 0.6000000238418579, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 10}\n",
      "{\"loss\": 0.6944533586502075, \"acc\": 0.5876789689064026, \"length\": 1.9993537664413452, \"mode\": \"train\", \"epoch\": 11}\n",
      "{\"loss\": 0.6777054071426392, \"acc\": 0.6000000238418579, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 11}\n",
      "{\"loss\": 0.6958145499229431, \"acc\": 0.5741121768951416, \"length\": 1.9983642101287842, \"mode\": \"train\", \"epoch\": 12}\n",
      "{\"loss\": 0.6764283180236816, \"acc\": 0.6000000238418579, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 12}\n",
      "{\"loss\": 0.7621669769287109, \"acc\": 0.562400221824646, \"length\": 1.999021291732788, \"mode\": \"train\", \"epoch\": 13}\n",
      "{\"loss\": 0.6912167072296143, \"acc\": 0.550000011920929, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 13}\n",
      "{\"loss\": 0.7135222554206848, \"acc\": 0.5624843239784241, \"length\": 1.9997453689575195, \"mode\": \"train\", \"epoch\": 14}\n",
      "{\"loss\": 0.6768943667411804, \"acc\": 0.6000000238418579, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 14}\n",
      "{\"loss\": 1.4967658519744873, \"acc\": 0.387519508600235, \"length\": 1.9996626377105713, \"mode\": \"train\", \"epoch\": 15}\n",
      "{\"loss\": 1.3928228616714478, \"acc\": 0.20000000298023224, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 15}\n",
      "{\"loss\": 1.3862167596817017, \"acc\": 0.2500024139881134, \"length\": 1.9957605600357056, \"mode\": \"train\", \"epoch\": 16}\n",
      "{\"loss\": 1.3923043012619019, \"acc\": 0.15000000596046448, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 16}\n",
      "{\"loss\": 1.3866989612579346, \"acc\": 0.2625017464160919, \"length\": 1.9995371103286743, \"mode\": \"train\", \"epoch\": 17}\n",
      "{\"loss\": 1.3909833431243896, \"acc\": 0.15000000596046448, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 17}\n",
      "{\"loss\": 1.3844845294952393, \"acc\": 0.25000086426734924, \"length\": 1.9995450973510742, \"mode\": \"train\", \"epoch\": 18}\n",
      "{\"loss\": 1.389697551727295, \"acc\": 0.15000000596046448, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 18}\n",
      "{\"loss\": 1.3840038776397705, \"acc\": 0.26249998807907104, \"length\": 1.9993808269500732, \"mode\": \"train\", \"epoch\": 19}\n",
      "{\"loss\": 1.3904592990875244, \"acc\": 0.15000000596046448, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 19}\n",
      "{\"loss\": 1.384629726409912, \"acc\": 0.2625012993812561, \"length\": 1.9994258880615234, \"mode\": \"train\", \"epoch\": 20}\n",
      "{\"loss\": 1.389155626296997, \"acc\": 0.15000000596046448, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 20}\n",
      "{\"loss\": 1.3827569484710693, \"acc\": 0.26250094175338745, \"length\": 1.9995758533477783, \"mode\": \"train\", \"epoch\": 21}\n",
      "{\"loss\": 1.3894505500793457, \"acc\": 0.20000000298023224, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 21}\n",
      "{\"loss\": 1.3795298337936401, \"acc\": 0.26249998807907104, \"length\": 1.998989462852478, \"mode\": \"train\", \"epoch\": 22}\n",
      "{\"loss\": 1.3893522024154663, \"acc\": 0.20000000298023224, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 22}\n",
      "{\"loss\": 1.3840460777282715, \"acc\": 0.2750079035758972, \"length\": 1.9996109008789062, \"mode\": \"train\", \"epoch\": 23}\n",
      "{\"loss\": 1.388551950454712, \"acc\": 0.25, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 23}\n",
      "{\"loss\": 1.3838903903961182, \"acc\": 0.28750211000442505, \"length\": 1.9995037317276, \"mode\": \"train\", \"epoch\": 24}\n",
      "{\"loss\": 1.3907444477081299, \"acc\": 0.25, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 24}\n",
      "{\"loss\": 1.3805654048919678, \"acc\": 0.27499866485595703, \"length\": 1.9997317790985107, \"mode\": \"train\", \"epoch\": 25}\n",
      "{\"loss\": 1.3909485340118408, \"acc\": 0.25, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 25}\n",
      "{\"loss\": 1.380530595779419, \"acc\": 0.28750088810920715, \"length\": 1.9993581771850586, \"mode\": \"train\", \"epoch\": 26}\n",
      "{\"loss\": 1.3973231315612793, \"acc\": 0.20000000298023224, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 26}\n",
      "{\"loss\": 1.3821470737457275, \"acc\": 0.3124823570251465, \"length\": 1.999354600906372, \"mode\": \"train\", \"epoch\": 27}\n",
      "{\"loss\": 1.3893911838531494, \"acc\": 0.20000000298023224, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 27}\n",
      "{\"loss\": 1.3805172443389893, \"acc\": 0.30000096559524536, \"length\": 1.9995224475860596, \"mode\": \"train\", \"epoch\": 28}\n",
      "{\"loss\": 1.3897864818572998, \"acc\": 0.25, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 28}\n",
      "{\"loss\": 1.3818174600601196, \"acc\": 0.28750520944595337, \"length\": 1.9995301961898804, \"mode\": \"train\", \"epoch\": 29}\n",
      "{\"loss\": 1.3927184343338013, \"acc\": 0.25, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 29}\n",
      "{\"loss\": 1.3813132047653198, \"acc\": 0.30000659823417664, \"length\": 1.9991729259490967, \"mode\": \"train\", \"epoch\": 30}\n",
      "{\"loss\": 1.3914481401443481, \"acc\": 0.25, \"length\": 2.0, \"mode\": \"test\", \"epoch\": 30}\n"
     ]
    }
   ],
   "source": [
    "game = core.SenderReceiverRnnGS(sender_gs, receiver_gs, loss_nll)\n",
    "\n",
    "opts = core.init(params=['--random_seed=7', \n",
    "                         '--lr=1e-2',   \n",
    "                         f'--batch_size={opts.batch_size}',\n",
    "                         '--optimizer=adam'])\n",
    "\n",
    "optimizer = torch.optim.Adam(game.parameters())\n",
    "\n",
    "trainer = core.Trainer(\n",
    "    game=game, \n",
    "    optimizer=optimizer, \n",
    "    train_data=train_loader,\n",
    "    validation_data=val_loader, \n",
    "    callbacks=[core.ConsoleLogger(as_json=True, print_train_loss=True)]\n",
    ")\n",
    "\n",
    "trainer.train(n_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Training improved when I put the GAT layer outside of the agents, but sometimes it gets to 0.6 acc and sometimes 0.35 so it's still a little weird. Also it goes down after a few epochs...\n",
    "- Batching is still not possible for sizes larger than 1. Which is not a very big problem but can become one if I need to run more epochs and bigger datasets.\n",
    "- Phong set `aux_input[k] = None` in interactions.py in order to be able to run with graphs, I did the same but I also set `receiver_output = None`. This is because when I used graphs of different sizes I kept getting errors, the output has a different size depending on the amount of nodes, and it kept expecting a tensor with dimensions of the first output. This is just for logging so I don't think it matters much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to explain my batching problem below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.],\n",
      "        [0.]]), tensor([3, 3]), None, DataBatch(x=[8, 2], edge_index=[2, 16], edge_attr=[16], target_node_idx=[2], batch=[8], ptr=[3]))\n",
      "====================================\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "tensor([3, 3])\n",
      "None\n",
      "DataBatch(x=[8, 2], edge_index=[2, 16], edge_attr=[16], target_node_idx=[2], batch=[8], ptr=[3])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(game_size=1, dataset=train_data, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(game_size=1, dataset=val_data, batch_size=2, shuffle=True)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(batch)\n",
    "print(\"====================================\")\n",
    "print(*batch, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch now contains 2 graphs, meaning 4x2=8 nodes. The labels are a tensor resulting from concatenating the specific target nodes of an individual graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  Data(x=[4, 2], edge_index=[2, 8], edge_attr=[8], target_node_idx=0)\n",
      "h: tensor([[3.4949e+00, 1.0353e+01, 3.4148e+01, 0.0000e+00, 0.0000e+00, 3.1618e+01,\n",
      "         2.0880e+01, 4.9061e+00, 0.0000e+00, 0.0000e+00, 7.5956e+00, 6.9070e+00,\n",
      "         0.0000e+00, 2.1370e+00, 1.2696e+01, 1.4778e+01, 2.1560e-01, 1.2968e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [3.4949e+00, 1.0353e+01, 3.4148e+01, 0.0000e+00, 0.0000e+00, 3.1618e+01,\n",
      "         2.0880e+01, 4.9061e+00, 0.0000e+00, 0.0000e+00, 7.6422e+00, 6.9264e+00,\n",
      "         0.0000e+00, 2.1913e+00, 1.2723e+01, 1.4853e+01, 2.0809e-01, 1.3289e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [3.6427e+00, 1.0457e+01, 3.4259e+01, 0.0000e+00, 0.0000e+00, 3.1818e+01,\n",
      "         2.0967e+01, 4.9298e+00, 0.0000e+00, 0.0000e+00, 5.3782e+00, 4.7993e+00,\n",
      "         0.0000e+00, 1.0397e+00, 1.0988e+01, 1.1264e+01, 3.0407e-01, 0.0000e+00,\n",
      "         5.0659e-01, 0.0000e+00],\n",
      "        [3.3749e+00, 1.0269e+01, 3.4058e+01, 0.0000e+00, 0.0000e+00, 3.1455e+01,\n",
      "         2.0810e+01, 4.8868e+00, 0.0000e+00, 0.0000e+00, 5.0175e+00, 4.9530e+00,\n",
      "         0.0000e+00, 5.4522e-01, 1.0765e+01, 1.0838e+01, 1.6734e-01, 0.0000e+00,\n",
      "         4.5720e-01, 0.0000e+00],\n",
      "        [3.6601e+00, 1.0888e+01, 3.5845e+01, 0.0000e+00, 0.0000e+00, 3.3215e+01,\n",
      "         2.1909e+01, 5.1207e+00, 0.0000e+00, 0.0000e+00, 7.5188e+00, 6.9213e+00,\n",
      "         0.0000e+00, 1.9272e+00, 1.2980e+01, 1.4781e+01, 2.4982e-01, 8.9243e-01,\n",
      "         2.1993e-02, 0.0000e+00],\n",
      "        [3.6601e+00, 1.0888e+01, 3.5845e+01, 0.0000e+00, 0.0000e+00, 3.3215e+01,\n",
      "         2.1909e+01, 5.1207e+00, 0.0000e+00, 0.0000e+00, 7.5076e+00, 6.8935e+00,\n",
      "         0.0000e+00, 1.9472e+00, 1.2964e+01, 1.4766e+01, 2.4299e-01, 8.6106e-01,\n",
      "         4.7338e-02, 0.0000e+00],\n",
      "        [3.7538e+00, 1.0904e+01, 3.5727e+01, 0.0000e+00, 0.0000e+00, 3.3178e+01,\n",
      "         2.1853e+01, 5.1133e+00, 0.0000e+00, 0.0000e+00, 5.5994e+00, 5.0477e+00,\n",
      "         0.0000e+00, 1.0493e+00, 1.1440e+01, 1.1724e+01, 3.1254e-01, 0.0000e+00,\n",
      "         5.2045e-01, 0.0000e+00],\n",
      "        [3.5229e+00, 1.0864e+01, 3.6017e+01, 0.0000e+00, 0.0000e+00, 3.3268e+01,\n",
      "         2.1991e+01, 5.1314e+00, 0.0000e+00, 0.0000e+00, 5.3124e+00, 5.2842e+00,\n",
      "         0.0000e+00, 5.5804e-01, 1.1368e+01, 1.1451e+01, 1.7863e-01, 0.0000e+00,\n",
      "         4.7569e-01, 0.0000e+00]], grad_fn=<ReluBackward0>)\n",
      "target_embedding: tensor([[ 3.3749, 10.2685, 34.0585,  0.0000,  0.0000, 31.4548, 20.8099,  4.8868,\n",
      "          0.0000,  0.0000,  5.0175,  4.9530,  0.0000,  0.5452, 10.7649, 10.8379,\n",
      "          0.1673,  0.0000,  0.4572,  0.0000],\n",
      "        [ 3.3749, 10.2685, 34.0585,  0.0000,  0.0000, 31.4548, 20.8099,  4.8868,\n",
      "          0.0000,  0.0000,  5.0175,  4.9530,  0.0000,  0.5452, 10.7649, 10.8379,\n",
      "          0.1673,  0.0000,  0.4572,  0.0000]], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sender_print = SenderPrint(embedding_size=10, hidden_size=20, temperature=1.0)\n",
    "\n",
    "sender_output, h, target_emb = sender_print(None, batch[3])\n",
    "\n",
    "print(\"Input: \", graph)\n",
    "print(\"h:\", h)\n",
    "print(\"target_embedding:\", target_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the output becomes (8 x embedding_size) because now there are 8 nodes. If you look at the indexing, for me the labels were 0 and 1, it takes the 0th and 1st element of the entire embedding. Meaning 2 nodes are passed from the first graph, and no nodes from the second graph. I need some way of knowing when a graph ends, which is easier when it is always the same size, but if I want more variation it doesn't work. I can't figure out how to solve this. Scatter would unwrap the batch but like I said it returns a mean or sum, which leaves out the possibility of identifyig the target node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender's shape:  torch.Size([2, 20])\n",
      "Receiver's shape:  torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Sender produces a message\n",
    "sender_output = sender(None, batch[3])\n",
    "#print(\"Sender's message:\", sender_output)\n",
    "print(\"Sender's shape: \", sender_output.shape)\n",
    "\n",
    "# Receiver tries to identify the target node\n",
    "receiver_output = receiver(sender_output, None, batch[3])\n",
    "#print(\"Receiver's output:\", receiver_output)\n",
    "print(\"Receiver's shape: \", receiver_output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
