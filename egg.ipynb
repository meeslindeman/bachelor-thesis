{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EGG Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import egg.core as core\n",
    "from torch.nn import functional as F\n",
    "from graph.dataset import FamilyGraphDataset\n",
    "from agents import Sender, Receiver\n",
    "from options import Options\n",
    "from dataloaders import create_data_loaders\n",
    "\n",
    "options = Options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Dataset is created by using the graph generating functions from \"graph\". The output is similar to the datasets used in PyTorch Geometric. A single graph Data object also has corresponding labels, which is a tensor of [num_nodes x 0] where one position is 1 (e.g. tensor([0, 0, 0, 1, 0])) for 5 nodes with target node 4. This is needed by the sender because I want it to send a description of the target node. It is later also needed in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: FamilyGraphDataset(100):\n",
      "====================\n",
      "Number of graphs: 100\n",
      "Number of features: 2\n",
      "\n",
      "Data(x=[9, 2], edge_index=[2, 22], edge_attr=[22], labels=[9])\n",
      "=============================================================\n",
      "Number of nodes: 9\n",
      "Number of edges: 22\n",
      "Labels: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = FamilyGraphDataset(root='/Users/meeslindeman/Library/Mobile Documents/com~apple~CloudDocs/Thesis/Code/data', number_of_graphs=100, generations=3)\n",
    "graph = dataset[0]\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print()\n",
    "print(graph)\n",
    "print('=============================================================')\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {graph.num_nodes}')\n",
    "print(f'Number of edges: {graph.num_edges}')\n",
    "print(f'Labels: {graph.labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching is done with dataloaders from dataloaders.py. They split the dataset iby 0.8/0.2 for training/testing. Batch size 3 therefore outputs 3 batches, totaling 8 graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Batches: 27\n",
      "Number of graphs in the current batch: 3\n",
      "DataBatch(x=[18, 2], edge_index=[2, 46], edge_attr=[46], labels=[18], batch=[18], ptr=[4])\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = create_data_loaders(dataset, batch_size=3)\n",
    "\n",
    "total_batches = len(train_loader)\n",
    "print(\"Total Batches:\", total_batches)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(f'Number of graphs in the current batch: {batch.num_graphs}')\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sender and receiver are instiated, embedding size is used for the size of the graph embedding. The final Linear layer will give output in hidden size as is expected by the EGG wrappers (see agents.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender(\n",
      "  (conv1): GATv2Conv(2, 32, heads=2)\n",
      "  (conv2): GATv2Conv(-1, 32, heads=2)\n",
      "  (fc): Linear(in_features=64, out_features=16, bias=True)\n",
      ")\n",
      "Receiver(\n",
      "  (conv1): GATv2Conv(2, 32, heads=2)\n",
      "  (conv2): GATv2Conv(-1, 32, heads=2)\n",
      "  (fc): Linear(in_features=16, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "sender = Sender(embedding_size=options.embedding_size, hidden_size=options.hidden_size, temperature=options.temp) \n",
    "print(sender)\n",
    "receiver = Receiver(embedding_size=options.embedding_size, hidden_size=options.hidden_size) \n",
    "print(receiver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we wrap the agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RnnSenderGS(\n",
      "  (agent): Sender(\n",
      "    (conv1): GATv2Conv(2, 32, heads=2)\n",
      "    (conv2): GATv2Conv(-1, 32, heads=2)\n",
      "    (fc): Linear(in_features=64, out_features=16, bias=True)\n",
      "  )\n",
      "  (hidden_to_output): Linear(in_features=16, out_features=20, bias=True)\n",
      "  (embedding): Linear(in_features=20, out_features=32, bias=True)\n",
      "  (cell): GRUCell(32, 16)\n",
      ")\n",
      "RnnReceiverGS(\n",
      "  (agent): Receiver(\n",
      "    (conv1): GATv2Conv(2, 32, heads=2)\n",
      "    (conv2): GATv2Conv(-1, 32, heads=2)\n",
      "    (fc): Linear(in_features=16, out_features=64, bias=True)\n",
      "  )\n",
      "  (cell): GRUCell(32, 16)\n",
      "  (embedding): Linear(in_features=20, out_features=32, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "sender_wrapped = core.RnnSenderGS(sender, options.vocab_size, options.embedding_size, options.hidden_size, max_len=5, temperature=1.0, cell=options.sender_cell)\n",
    "sender_gs = core.GumbelSoftmaxWrapper(sender, temperature=1.0)\n",
    "print(sender_wrapped)\n",
    "\n",
    "receiver_wrapped = core.RnnReceiverGS(receiver, options.vocab_size, options.embedding_size, options.hidden_size, cell=options.sender_cell)\n",
    "receiver_gs = core.SymbolReceiverWrapper(receiver, vocab_size=options.vocab_size, agent_input_size=options.hidden_size)\n",
    "print(receiver_wrapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the receiver is of shape (nodes x max_len+1 x num_classes). Num_classes is 2 since I want the receiver to ouput probabilities for each class (target node or no target node). I do this because the loss function that is eventually used requires receiver output and labels to calculate the loss. Previously I had the receiver output one probabilty per node but this didn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender's shape: torch.Size([1, 6, 20])\n",
      "Receiver's shape: torch.Size([9, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "# Sender produces a message\n",
    "sender_output = sender_wrapped(graph)\n",
    "#print(\"Sender's message:\", sender_output)\n",
    "print(\"Sender's shape:\", sender_output.shape) # batch size x max_len+1 x vocab size\n",
    "\n",
    "# Receiver tries to identify the target node\n",
    "receiver_output = receiver_wrapped(sender_output, graph)\n",
    "#print(\"Receiver's output:\", receiver_output)\n",
    "print(\"Receiver's shape:\", receiver_output.shape) # nodes x max_len+1 x num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the loss function, we need the receiver output and labels to calculate the loss. The interaction, however, gives problems as you can see later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1111, grad_fn=<MeanBackward0>)\n",
      "====================================\n",
      "Interaction(sender_input=Data(x=[9, 2], edge_index=[2, 22], edge_attr=[22], labels=[9]), receiver_input=Data(x=[9, 2], edge_index=[2, 22], edge_attr=[22], labels=[9]), labels=tensor([0, 1, 0, 0, 0, 0, 0, 0, 0]), aux_input=None, message=tensor([[[9.5213e-03, 7.4491e-03, 2.2523e-03, 6.8643e-02, 7.9756e-03,\n",
      "          5.2132e-03, 5.1704e-02, 2.5034e-04, 8.4826e-02, 3.3761e-03,\n",
      "          5.6289e-03, 4.5174e-03, 6.8774e-04, 3.9150e-02, 6.3565e-02,\n",
      "          5.2750e-03, 1.4432e-03, 2.5779e-04, 3.9017e-01, 2.4809e-01],\n",
      "         [5.2824e-03, 4.1476e-02, 7.9926e-03, 2.7547e-01, 3.0722e-02,\n",
      "          2.6026e-03, 1.5556e-01, 3.4094e-03, 5.9376e-02, 9.7753e-02,\n",
      "          6.4214e-02, 9.1295e-02, 3.9879e-04, 7.0249e-03, 1.7666e-02,\n",
      "          5.0102e-03, 1.1797e-03, 5.7303e-03, 3.4935e-02, 9.2902e-02],\n",
      "         [4.3903e-02, 2.2493e-02, 1.7936e-03, 3.8288e-02, 1.9507e-02,\n",
      "          8.2004e-03, 7.8642e-02, 7.0019e-03, 2.2240e-02, 1.5049e-02,\n",
      "          1.6740e-02, 5.5062e-03, 1.3493e-03, 3.1337e-02, 5.0245e-01,\n",
      "          1.4489e-02, 1.9190e-03, 1.2853e-02, 9.7768e-02, 5.8471e-02],\n",
      "         [2.0223e-02, 7.3324e-02, 8.6810e-04, 3.5950e-02, 3.0259e-02,\n",
      "          2.2268e-02, 5.7980e-02, 9.1971e-03, 4.4733e-02, 5.2653e-02,\n",
      "          2.3439e-02, 2.8865e-02, 1.2231e-02, 1.8400e-01, 7.0489e-03,\n",
      "          3.4740e-02, 5.9736e-03, 2.7021e-03, 3.0054e-02, 3.2349e-01],\n",
      "         [1.6171e-03, 8.4601e-03, 2.2757e-03, 1.7854e-02, 2.6706e-03,\n",
      "          1.7351e-03, 1.1496e-02, 3.9158e-03, 3.9172e-02, 6.9737e-03,\n",
      "          9.2047e-03, 8.8874e-03, 1.5884e-03, 8.3324e-01, 2.1306e-03,\n",
      "          4.8463e-03, 2.4428e-03, 3.6809e-03, 6.2929e-03, 3.1511e-02],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]), receiver_output=tensor([[[0.0377, 0.0377],\n",
      "         [0.0245, 0.0245],\n",
      "         [0.0096, 0.0096],\n",
      "         [0.0122, 0.0122],\n",
      "         [0.0096, 0.0096],\n",
      "         [0.0208, 0.0208]],\n",
      "\n",
      "        [[0.0379, 0.0379],\n",
      "         [0.0246, 0.0246],\n",
      "         [0.0097, 0.0097],\n",
      "         [0.0122, 0.0122],\n",
      "         [0.0096, 0.0096],\n",
      "         [0.0208, 0.0208]],\n",
      "\n",
      "        [[0.1493, 0.1493],\n",
      "         [0.1563, 0.1563],\n",
      "         [0.1642, 0.1642],\n",
      "         [0.1626, 0.1626],\n",
      "         [0.1623, 0.1623],\n",
      "         [0.1561, 0.1561]],\n",
      "\n",
      "        [[0.1546, 0.1546],\n",
      "         [0.1636, 0.1636],\n",
      "         [0.1743, 0.1743],\n",
      "         [0.1724, 0.1724],\n",
      "         [0.1715, 0.1715],\n",
      "         [0.1654, 0.1654]],\n",
      "\n",
      "        [[0.1388, 0.1388],\n",
      "         [0.1492, 0.1492],\n",
      "         [0.1665, 0.1665],\n",
      "         [0.1630, 0.1630],\n",
      "         [0.1748, 0.1748],\n",
      "         [0.1572, 0.1572]],\n",
      "\n",
      "        [[0.1454, 0.1454],\n",
      "         [0.1573, 0.1573],\n",
      "         [0.1778, 0.1778],\n",
      "         [0.1732, 0.1732],\n",
      "         [0.1845, 0.1845],\n",
      "         [0.1640, 0.1640]],\n",
      "\n",
      "        [[0.1680, 0.1680],\n",
      "         [0.1823, 0.1823],\n",
      "         [0.2014, 0.2014],\n",
      "         [0.1982, 0.1982],\n",
      "         [0.1944, 0.1944],\n",
      "         [0.1876, 0.1876]],\n",
      "\n",
      "        [[0.0943, 0.0943],\n",
      "         [0.0826, 0.0826],\n",
      "         [0.0592, 0.0592],\n",
      "         [0.0646, 0.0646],\n",
      "         [0.0568, 0.0568],\n",
      "         [0.0767, 0.0767]],\n",
      "\n",
      "        [[0.0740, 0.0740],\n",
      "         [0.0596, 0.0596],\n",
      "         [0.0373, 0.0373],\n",
      "         [0.0416, 0.0416],\n",
      "         [0.0366, 0.0366],\n",
      "         [0.0514, 0.0514]]]), message_length=tensor([5.7621, 5.7621, 5.7621, 5.7621, 5.7621, 5.7621, 5.7621, 5.7621, 5.7621]), aux={'acc': tensor([0.8889, 0.8889, 0.8889, 0.8889, 0.8889, 0.8889, 0.8889, 0.8889, 0.8889],\n",
      "       grad_fn=<AddBackward0>), 'length': tensor([5.7621, 5.7621, 5.7621, 5.7621, 5.7621, 5.7621, 5.7621, 5.7621, 5.7621],\n",
      "       grad_fn=<AddBackward0>)})\n"
     ]
    }
   ],
   "source": [
    "def loss_nll(\n",
    "    _sender_input, _message, _receiver_input, receiver_output, labels, _aux_input):\n",
    "    \"\"\"\n",
    "    NLL loss - differentiable and can be used with both GS and Reinforce\n",
    "    \"\"\"\n",
    "    nll = F.nll_loss(receiver_output, labels, reduction=\"none\")\n",
    "    acc = (labels == receiver_output.argmax(dim=1)).float().mean()\n",
    "    return nll, {\"acc\": acc}\n",
    "\n",
    "game = core.SenderReceiverRnnGS(sender_wrapped, receiver_wrapped, loss_nll)\n",
    "\n",
    "loss, interaction = game(sender_input=graph, labels=graph.labels, receiver_input=graph, aux_input=None)\n",
    "print(loss)\n",
    "print(\"====================================\")\n",
    "print(interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to modify the Batch class that is used in the egg.Trainer function because it used to unwrap an expected batch with tensors, which Phong showed in his method. I modified it to handle the DataBatch object by Torch Geometric differently. Now it unwraps the graphs and the labels. I need the receiver to handle the same graph (we spoke about masking earlier but this gave so many problem that I held it off for now), so the sender input and receiver input are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from egg.core.util import move_to\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "\n",
    "class CustomBatch:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_batch: Batch,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        receiver_input: Optional[Any] = None,\n",
    "        aux_input: Optional[Dict[Any, Any]] = None,\n",
    "\n",
    "    ):\n",
    "        self.data_batch = data_batch\n",
    "        for i in range(len(self.data_batch)):\n",
    "            self.sender_input = data_batch.get_example(i)\n",
    "            self.labels = data_batch.labels[:self.sender_input.num_nodes]\n",
    "            self.receiver_input = data_batch.get_example(i)\n",
    "            self.aux_input = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        >>> b = Batch(torch.Tensor([1]), torch.Tensor([2]), torch.Tensor([3]), {})\n",
    "        >>> b[0]\n",
    "        tensor([1.])\n",
    "        >>> b[1]\n",
    "        tensor([2.])\n",
    "        >>> b[2]\n",
    "        tensor([3.])\n",
    "        >>> b[3]\n",
    "        {}\n",
    "        >>> b[6]\n",
    "        Traceback (most recent call last):\n",
    "            ...\n",
    "        IndexError: Trying to access a wrong index in the batch\n",
    "        \"\"\"\n",
    "        if idx == 0:\n",
    "            return self.sender_input\n",
    "        elif idx == 1:\n",
    "            return self.labels\n",
    "        elif idx == 2:\n",
    "            return self.receiver_input\n",
    "        elif idx == 3:\n",
    "            return self.aux_input\n",
    "        else:\n",
    "            raise IndexError(\"Trying to access a wrong index in the batch\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        >>> _ = torch.manual_seed(111)\n",
    "        >>> sender_input = torch.rand(2, 2)\n",
    "        >>> labels = torch.rand(2, 2)\n",
    "        >>> batch = Batch(sender_input, labels)\n",
    "        >>> it = batch.__iter__()\n",
    "        >>> it_sender_input = next(it)\n",
    "        >>> torch.allclose(sender_input, it_sender_input)\n",
    "        True\n",
    "        >>> it_labels = next(it)\n",
    "        >>> torch.allclose(labels, it_labels)\n",
    "        True\n",
    "        \"\"\"\n",
    "        return iter(\n",
    "            [self.sender_input, self.labels, self.receiver_input, self.aux_input]\n",
    "        )\n",
    "\n",
    "    def to(self, device: torch.device):\n",
    "        \"\"\"Method to move all (nested) tensors of the batch to a specific device.\n",
    "        This operation doest not change the original batch element and returns a new Batch instance.\n",
    "        \"\"\"\n",
    "        self.sender_input = move_to(self.sender_input, device)\n",
    "        self.labels = move_to(self.labels, device)\n",
    "        self.receiver_input = move_to(self.receiver_input, device)\n",
    "        self.aux_input = move_to(self.aux_input, device)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type as it is passed to the CustomBatch class:\n",
      "========================================\n",
      "DataBatch(x=[18, 2], edge_index=[2, 46], edge_attr=[46], labels=[18], batch=[18], ptr=[4])\n",
      "\n",
      "Batch information after it is passed to the CustomBatch class:\n",
      "========================================\n",
      "Sender input: Data(x=[5, 2], edge_index=[2, 12], edge_attr=[12], labels=[5])\n",
      "Labels: tensor([0, 0, 1, 0, 0])\n",
      "Receiver input: Data(x=[5, 2], edge_index=[2, 12], edge_attr=[12], labels=[5])\n",
      "Aux input: None\n",
      "\n",
      "Output of the game (as it is called in the train function):\n",
      "========================================\n",
      "tensor(-0.2000, grad_fn=<MeanBackward0>)\n",
      "Interaction(sender_input=Data(x=[5, 2], edge_index=[2, 12], edge_attr=[12], labels=[5]), receiver_input=Data(x=[5, 2], edge_index=[2, 12], edge_attr=[12], labels=[5]), labels=tensor([0, 0, 1, 0, 0]), aux_input=None, message=tensor([[[2.0549e-02, 1.1745e-02, 3.7538e-04, 4.5080e-01, 5.9699e-03,\n",
      "          2.2580e-03, 8.0914e-02, 2.4243e-04, 6.1061e-03, 9.8548e-03,\n",
      "          7.7322e-03, 7.4713e-04, 1.0265e-04, 3.5962e-02, 2.3592e-01,\n",
      "          2.2852e-02, 6.2252e-04, 1.9337e-03, 9.3854e-02, 1.1455e-02],\n",
      "         [2.9647e-03, 1.9219e-02, 5.5880e-04, 4.1244e-02, 5.3291e-03,\n",
      "          2.3643e-02, 1.5495e-02, 1.1311e-03, 3.7418e-03, 2.7077e-02,\n",
      "          2.9674e-02, 4.8947e-03, 1.9589e-04, 7.1967e-03, 1.2307e-01,\n",
      "          2.2020e-02, 9.1885e-03, 1.1333e-03, 5.1903e-01, 1.4319e-01],\n",
      "         [2.6863e-03, 5.2700e-03, 1.5802e-03, 5.9475e-01, 7.2475e-02,\n",
      "          3.0168e-03, 4.0336e-02, 2.3364e-03, 1.8837e-02, 1.8443e-02,\n",
      "          7.6703e-02, 1.8636e-02, 5.1613e-03, 3.4518e-02, 1.2764e-02,\n",
      "          1.1965e-02, 2.8537e-02, 6.5750e-03, 2.1994e-02, 2.3419e-02],\n",
      "         [9.4604e-03, 4.0590e-02, 1.0031e-03, 2.4009e-02, 2.7272e-02,\n",
      "          2.2025e-02, 8.7224e-03, 1.5130e-03, 3.5507e-02, 3.5609e-01,\n",
      "          6.4498e-03, 1.1994e-01, 1.8151e-03, 6.2944e-02, 1.0592e-02,\n",
      "          2.0535e-01, 5.7197e-03, 1.4615e-02, 2.3126e-02, 2.3261e-02],\n",
      "         [4.8931e-02, 6.6219e-02, 2.5003e-03, 1.8198e-02, 6.0301e-02,\n",
      "          2.1486e-02, 3.4327e-02, 1.3997e-01, 8.8312e-02, 2.9109e-02,\n",
      "          5.5436e-03, 6.1194e-02, 6.3119e-03, 7.0050e-02, 1.4527e-02,\n",
      "          9.3911e-02, 6.1839e-02, 9.0409e-03, 3.0592e-02, 1.3764e-01],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]), receiver_output=tensor([[[0.0389, 0.0389],\n",
      "         [0.0340, 0.0340],\n",
      "         [0.0258, 0.0258],\n",
      "         [0.0354, 0.0354],\n",
      "         [0.0285, 0.0285],\n",
      "         [0.0385, 0.0385]],\n",
      "\n",
      "        [[0.0400, 0.0400],\n",
      "         [0.0348, 0.0348],\n",
      "         [0.0265, 0.0265],\n",
      "         [0.0363, 0.0363],\n",
      "         [0.0293, 0.0293],\n",
      "         [0.0393, 0.0393]],\n",
      "\n",
      "        [[0.3361, 0.3361],\n",
      "         [0.3458, 0.3458],\n",
      "         [0.3572, 0.3572],\n",
      "         [0.3435, 0.3435],\n",
      "         [0.3526, 0.3526],\n",
      "         [0.3417, 0.3417]],\n",
      "\n",
      "        [[0.3378, 0.3378],\n",
      "         [0.3448, 0.3448],\n",
      "         [0.3553, 0.3553],\n",
      "         [0.3433, 0.3433],\n",
      "         [0.3517, 0.3517],\n",
      "         [0.3407, 0.3407]],\n",
      "\n",
      "        [[0.2473, 0.2473],\n",
      "         [0.2406, 0.2406],\n",
      "         [0.2351, 0.2351],\n",
      "         [0.2415, 0.2415],\n",
      "         [0.2378, 0.2378],\n",
      "         [0.2398, 0.2398]]]), message_length=tensor([5.8121, 5.8121, 5.8121, 5.8121, 5.8121]), aux={'acc': tensor([0.8000, 0.8000, 0.8000, 0.8000, 0.8000], grad_fn=<AddBackward0>), 'length': tensor([5.8121, 5.8121, 5.8121, 5.8121, 5.8121], grad_fn=<AddBackward0>)})\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch type as it is passed to the CustomBatch class:\")\n",
    "print(\"========================================\")\n",
    "print(batch)\n",
    "print()\n",
    "\n",
    "print(\"Batch information after it is passed to the CustomBatch class:\")\n",
    "print(\"========================================\")\n",
    "class_output = CustomBatch(batch)\n",
    "print(\"Sender input:\", class_output.sender_input)\n",
    "print(\"Labels:\", class_output.labels)\n",
    "print(\"Receiver input:\", class_output.receiver_input)\n",
    "print(\"Aux input:\", class_output.aux_input)\n",
    "print()\n",
    "\n",
    "print(\"Output of the game (as it is called in the train function):\")\n",
    "print(\"========================================\")\n",
    "loss, interaction = game(*class_output)\n",
    "print(loss)\n",
    "print(interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Trainer function also has to be modified to pass the batch type through the right Batch class, which is now CustomBatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From EGG:\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "from typing import List, Optional\n",
    "\n",
    "try:\n",
    "    # requires python >= 3.7\n",
    "    from contextlib import nullcontext\n",
    "except ImportError:\n",
    "    # not exactly the same, but will do for our purposes\n",
    "    from contextlib import suppress as nullcontext\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from egg.core.batch import Batch\n",
    "from egg.core.callbacks import (\n",
    "    Callback,\n",
    "    Checkpoint,\n",
    "    CheckpointSaver,\n",
    "    ConsoleLogger,\n",
    "    TensorboardLogger,\n",
    ")\n",
    "from egg.core.distributed import get_preemptive_checkpoint_dir\n",
    "from egg.core.interaction import Interaction\n",
    "from egg.core.util import get_opts, move_to\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import GradScaler, autocast\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "class CustomTrainer:\n",
    "    \"\"\"\n",
    "    Implements the training logic. Some common configuration (checkpointing frequency, path, validation frequency)\n",
    "    is done by checking util.common_opts that is set via the CL.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        game: torch.nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        train_data: DataLoader,\n",
    "        optimizer_scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,\n",
    "        validation_data: Optional[DataLoader] = None,\n",
    "        device: torch.device = None,\n",
    "        callbacks: Optional[List[Callback]] = None,\n",
    "        grad_norm: float = None,\n",
    "        aggregate_interaction_logs: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param game: A nn.Module that implements forward(); it is expected that forward returns a tuple of (loss, d),\n",
    "            where loss is differentiable loss to be minimized and d is a dictionary (potentially empty) with auxiliary\n",
    "            metrics that would be aggregated and reported\n",
    "        :param optimizer: An instance of torch.optim.Optimizer\n",
    "        :param optimizer_scheduler: An optimizer scheduler to adjust lr throughout training\n",
    "        :param train_data: A DataLoader for the training set\n",
    "        :param validation_data: A DataLoader for the validation set (can be None)\n",
    "        :param device: A torch.device on which to tensors should be stored\n",
    "        :param callbacks: A list of egg.core.Callback objects that can encapsulate monitoring or checkpointing\n",
    "        \"\"\"\n",
    "        self.game = game\n",
    "        self.optimizer = optimizer\n",
    "        self.optimizer_scheduler = optimizer_scheduler\n",
    "        self.train_data = train_data\n",
    "        self.validation_data = validation_data\n",
    "        common_opts = get_opts()\n",
    "        self.validation_freq = common_opts.validation_freq\n",
    "        self.device = common_opts.device if device is None else device\n",
    "\n",
    "        self.should_stop = False\n",
    "        self.start_epoch = 0  # Can be overwritten by checkpoint loader\n",
    "        self.callbacks = callbacks if callbacks else []\n",
    "        self.grad_norm = grad_norm\n",
    "        self.aggregate_interaction_logs = aggregate_interaction_logs\n",
    "\n",
    "        self.update_freq = common_opts.update_freq\n",
    "\n",
    "        if common_opts.load_from_checkpoint is not None:\n",
    "            print(\n",
    "                f\"# Initializing model, trainer, and optimizer from {common_opts.load_from_checkpoint}\"\n",
    "            )\n",
    "            self.load_from_checkpoint(common_opts.load_from_checkpoint)\n",
    "\n",
    "        self.distributed_context = common_opts.distributed_context\n",
    "        if self.distributed_context.is_distributed:\n",
    "            print(\"# Distributed context: \", self.distributed_context)\n",
    "\n",
    "        if self.distributed_context.is_leader and not any(\n",
    "            isinstance(x, CheckpointSaver) for x in self.callbacks\n",
    "        ):\n",
    "            if common_opts.preemptable:\n",
    "                assert (\n",
    "                    common_opts.checkpoint_dir\n",
    "                ), \"checkpointing directory has to be specified\"\n",
    "                d = get_preemptive_checkpoint_dir(common_opts.checkpoint_dir)\n",
    "                self.checkpoint_path = d\n",
    "                self.load_from_latest(d)\n",
    "            else:\n",
    "                self.checkpoint_path = (\n",
    "                    None\n",
    "                    if common_opts.checkpoint_dir is None\n",
    "                    else pathlib.Path(common_opts.checkpoint_dir)\n",
    "                )\n",
    "\n",
    "            if self.checkpoint_path:\n",
    "                checkpointer = CheckpointSaver(\n",
    "                    checkpoint_path=self.checkpoint_path,\n",
    "                    checkpoint_freq=common_opts.checkpoint_freq,\n",
    "                )\n",
    "                self.callbacks.append(checkpointer)\n",
    "\n",
    "        if self.distributed_context.is_leader and common_opts.tensorboard:\n",
    "            assert (\n",
    "                common_opts.tensorboard_dir\n",
    "            ), \"tensorboard directory has to be specified\"\n",
    "            tensorboard_logger = TensorboardLogger()\n",
    "            self.callbacks.append(tensorboard_logger)\n",
    "\n",
    "        if self.callbacks is None:\n",
    "            self.callbacks = [\n",
    "                ConsoleLogger(print_train_loss=False, as_json=False),\n",
    "            ]\n",
    "\n",
    "        if self.distributed_context.is_distributed:\n",
    "            device_id = self.distributed_context.local_rank\n",
    "            torch.cuda.set_device(device_id)\n",
    "            self.game.to(device_id)\n",
    "\n",
    "            # NB: here we are doing something that is a bit shady:\n",
    "            # 1/ optimizer was created outside of the Trainer instance, so we don't really know\n",
    "            #    what parameters it optimizes. If it holds something what is not within the Game instance\n",
    "            #    then it will not participate in distributed training\n",
    "            # 2/ if optimizer only holds a subset of Game parameters, it works, but somewhat non-documentedly.\n",
    "            #    In fact, optimizer would hold parameters of non-DistributedDataParallel version of the Game. The\n",
    "            #    forward/backward calls, however, would happen on the DistributedDataParallel wrapper.\n",
    "            #    This wrapper would sync gradients of the underlying tensors - which are the ones that optimizer\n",
    "            #    holds itself.  As a result it seems to work, but only because DDP doesn't take any tensor ownership.\n",
    "\n",
    "            self.game = torch.nn.parallel.DistributedDataParallel(\n",
    "                self.game,\n",
    "                device_ids=[device_id],\n",
    "                output_device=device_id,\n",
    "                find_unused_parameters=True,\n",
    "            )\n",
    "            self.optimizer.state = move_to(self.optimizer.state, device_id)\n",
    "\n",
    "        else:\n",
    "            self.game.to(self.device)\n",
    "            # NB: some optimizers pre-allocate buffers before actually doing any steps\n",
    "            # since model is placed on GPU within Trainer, this leads to having optimizer's state and model parameters\n",
    "            # on different devices. Here, we protect from that by moving optimizer's internal state to the proper device\n",
    "            self.optimizer.state = move_to(self.optimizer.state, self.device)\n",
    "\n",
    "        if common_opts.fp16:\n",
    "            self.scaler = GradScaler()\n",
    "        else:\n",
    "            self.scaler = None\n",
    "\n",
    "    def eval(self, data=None):\n",
    "        mean_loss = 0.0\n",
    "        interactions = []\n",
    "        n_batches = 0\n",
    "        validation_data = self.validation_data if data is None else data\n",
    "        self.game.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in validation_data:\n",
    "                if not isinstance(batch, Batch):\n",
    "                    batch = CustomBatch(batch) # MODIFIED\n",
    "                batch = batch.to(self.device)\n",
    "                optimized_loss, interaction = self.game(*batch)\n",
    "                if (\n",
    "                    self.distributed_context.is_distributed\n",
    "                    and self.aggregate_interaction_logs\n",
    "                ):\n",
    "                    interaction = Interaction.gather_distributed_interactions(\n",
    "                        interaction\n",
    "                    )\n",
    "                interaction = interaction.to(\"cpu\")\n",
    "                mean_loss += optimized_loss\n",
    "\n",
    "                for callback in self.callbacks:\n",
    "                    callback.on_batch_end(\n",
    "                        interaction, optimized_loss, n_batches, is_training=False\n",
    "                    )\n",
    "\n",
    "                interactions.append(interaction)\n",
    "                n_batches += 1\n",
    "\n",
    "        mean_loss /= n_batches\n",
    "        full_interaction = Interaction.from_iterable(interactions)\n",
    "\n",
    "        return mean_loss.item(), full_interaction\n",
    "\n",
    "    def train_epoch(self):\n",
    "        mean_loss = 0\n",
    "        n_batches = 0\n",
    "        interactions = []\n",
    "\n",
    "        self.game.train()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        for batch_id, batch in enumerate(self.train_data):\n",
    "            if not isinstance(batch, Batch):\n",
    "                batch = CustomBatch(batch) # MODIFIED\n",
    "            batch = batch.to(self.device)\n",
    "\n",
    "\n",
    "            context = autocast() if self.scaler else nullcontext()\n",
    "            with context:\n",
    "                optimized_loss, interaction = self.game(*batch)\n",
    "\n",
    "                if self.update_freq > 1:\n",
    "                    # throughout EGG, we minimize _mean_ loss, not sum\n",
    "                    # hence, we need to account for that when aggregating grads\n",
    "                    optimized_loss = optimized_loss / self.update_freq\n",
    "\n",
    "            if self.scaler:\n",
    "                self.scaler.scale(optimized_loss).backward()\n",
    "            else:\n",
    "                optimized_loss.backward()\n",
    "\n",
    "            if batch_id % self.update_freq == self.update_freq - 1:\n",
    "                if self.scaler:\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "\n",
    "                if self.grad_norm:\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        self.game.parameters(), self.grad_norm\n",
    "                    )\n",
    "                if self.scaler:\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "            n_batches += 1\n",
    "            mean_loss += optimized_loss.detach()\n",
    "            if (\n",
    "                self.distributed_context.is_distributed\n",
    "                and self.aggregate_interaction_logs\n",
    "            ):\n",
    "                interaction = Interaction.gather_distributed_interactions(interaction)\n",
    "            interaction = interaction.to(\"cpu\")\n",
    "\n",
    "            for callback in self.callbacks:\n",
    "                callback.on_batch_end(interaction, optimized_loss, batch_id)\n",
    "\n",
    "            interactions.append(interaction)\n",
    "\n",
    "        if self.optimizer_scheduler:\n",
    "            self.optimizer_scheduler.step()\n",
    "\n",
    "        mean_loss /= n_batches\n",
    "        full_interaction = Interaction.from_iterable(interactions)\n",
    "        return mean_loss.item(), full_interaction\n",
    "\n",
    "    def train(self, n_epochs):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_begin(self)\n",
    "\n",
    "        for epoch in range(self.start_epoch, n_epochs):\n",
    "            for callback in self.callbacks:\n",
    "                callback.on_epoch_begin(epoch + 1)\n",
    "\n",
    "            train_loss, train_interaction = self.train_epoch()\n",
    "\n",
    "            for callback in self.callbacks:\n",
    "                callback.on_epoch_end(train_loss, train_interaction, epoch + 1)\n",
    "\n",
    "            validation_loss = validation_interaction = None\n",
    "            if (\n",
    "                self.validation_data is not None\n",
    "                and self.validation_freq > 0\n",
    "                and (epoch + 1) % self.validation_freq == 0\n",
    "            ):\n",
    "                for callback in self.callbacks:\n",
    "                    callback.on_validation_begin(epoch + 1)\n",
    "                validation_loss, validation_interaction = self.eval()\n",
    "\n",
    "                for callback in self.callbacks:\n",
    "                    callback.on_validation_end(\n",
    "                        validation_loss, validation_interaction, epoch + 1\n",
    "                    )\n",
    "\n",
    "            if self.should_stop:\n",
    "                for callback in self.callbacks:\n",
    "                    callback.on_early_stopping(\n",
    "                        train_loss,\n",
    "                        train_interaction,\n",
    "                        epoch + 1,\n",
    "                        validation_loss,\n",
    "                        validation_interaction,\n",
    "                    )\n",
    "                break\n",
    "\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_end()\n",
    "\n",
    "    def load(self, checkpoint: Checkpoint):\n",
    "        self.game.load_state_dict(checkpoint.model_state_dict)\n",
    "        self.optimizer.load_state_dict(checkpoint.optimizer_state_dict)\n",
    "        if checkpoint.optimizer_scheduler_state_dict:\n",
    "            self.optimizer_scheduler.load_state_dict(\n",
    "                checkpoint.optimizer_scheduler_state_dict\n",
    "            )\n",
    "        self.start_epoch = checkpoint.epoch\n",
    "\n",
    "    def load_from_checkpoint(self, path):\n",
    "        \"\"\"\n",
    "        Loads the game, agents, and optimizer state from a file\n",
    "        :param path: Path to the file\n",
    "        \"\"\"\n",
    "        print(f\"# loading trainer state from {path}\")\n",
    "        checkpoint = torch.load(path)\n",
    "        self.load(checkpoint)\n",
    "\n",
    "    def load_from_latest(self, path):\n",
    "        latest_file, latest_time = None, None\n",
    "\n",
    "        for file in path.glob(\"*.tar\"):\n",
    "            creation_time = os.stat(file).st_ctime\n",
    "            if latest_time is None or creation_time > latest_time:\n",
    "                latest_file, latest_time = file, creation_time\n",
    "\n",
    "        if latest_file is not None:\n",
    "            self.load_from_checkpoint(latest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import RelaxedOneHotCategorical\n",
    "\n",
    "from egg.core.interaction import LoggingStrategy\n",
    "\n",
    "class CustomSenderReceiverRnnGS(nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements the Sender/Receiver game mechanics for the Sender/Receiver game with variable-length\n",
    "    communication messages and Gumber-Softmax relaxation of the channel. The vocabulary term with id `0` is assumed\n",
    "    to the end-of-sequence symbol. It is assumed that communication is stopped either after all the message is processed\n",
    "    or when the end-of-sequence symbol is met.\n",
    "\n",
    "    >>> class Sender(nn.Module):\n",
    "    ...     def __init__(self):\n",
    "    ...         super().__init__()\n",
    "    ...         self.fc = nn.Linear(10, 5)\n",
    "    ...     def forward(self, x, _input=None, aux_input=None):\n",
    "    ...         return self.fc(x)\n",
    "    >>> sender = Sender()\n",
    "    >>> sender = RnnSenderGS(sender, vocab_size=2, embed_dim=3, hidden_size=5, max_len=3, temperature=5.0, cell='gru')\n",
    "    >>> class Receiver(nn.Module):\n",
    "    ...     def __init__(self):\n",
    "    ...         super().__init__()\n",
    "    ...         self.fc = nn.Linear(7, 10)\n",
    "    ...     def forward(self, x, _input=None, aux_input=None):\n",
    "    ...         return self.fc(x)\n",
    "    >>> receiver = RnnReceiverGS(Receiver(), vocab_size=2, embed_dim=4, hidden_size=7, cell='rnn')\n",
    "    >>> def loss(sender_input, _message, _receiver_input, receiver_output, labels, aux_input):\n",
    "    ...     return (sender_input - receiver_output).pow(2.0).mean(dim=1), {'aux': torch.zeros(sender_input.size(0))}\n",
    "    >>> game = SenderReceiverRnnGS(sender, receiver, loss)\n",
    "    >>> loss, interaction = game(torch.ones((3, 10)), None, None)  # batch of 3 10d vectors\n",
    "    >>> interaction.aux['aux'].detach()\n",
    "    tensor([0., 0., 0.])\n",
    "    >>> loss.item() > 0\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sender,\n",
    "        receiver,\n",
    "        loss,\n",
    "        length_cost=0.0,\n",
    "        train_logging_strategy: Optional[LoggingStrategy] = None,\n",
    "        test_logging_strategy: Optional[LoggingStrategy] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param sender: sender agent\n",
    "        :param receiver: receiver agent\n",
    "        :param loss:  the optimized loss that accepts\n",
    "            sender_input: input of Sender\n",
    "            message: the is sent by Sender\n",
    "            receiver_input: input of Receiver from the dataset\n",
    "            receiver_output: output of Receiver\n",
    "            labels: labels assigned to Sender's input data\n",
    "          and outputs a tuple of (1) a loss tensor of shape (batch size, 1) (2) the dict with auxiliary information\n",
    "          of the same shape. The loss will be minimized during training, and the auxiliary information aggregated over\n",
    "          all batches in the dataset.\n",
    "        :param length_cost: the penalty applied to Sender for each symbol produced\n",
    "        :param train_logging_strategy, test_logging_strategy: specify what parts of interactions to persist for\n",
    "            later analysis in the callbacks.\n",
    "\n",
    "        \"\"\"\n",
    "        super(CustomSenderReceiverRnnGS, self).__init__()\n",
    "        self.sender = sender\n",
    "        self.receiver = receiver\n",
    "        self.loss = loss\n",
    "        self.length_cost = length_cost\n",
    "        self.train_logging_strategy = (\n",
    "            LoggingStrategy()\n",
    "            if train_logging_strategy is None\n",
    "            else train_logging_strategy\n",
    "        )\n",
    "        self.test_logging_strategy = (\n",
    "            LoggingStrategy()\n",
    "            if test_logging_strategy is None\n",
    "            else test_logging_strategy\n",
    "        )\n",
    "\n",
    "    def forward(self, sender_input, labels, receiver_input=None, aux_input=None):\n",
    "        message = self.sender(sender_input, aux_input)\n",
    "        receiver_output = self.receiver(message, receiver_input, aux_input)\n",
    "\n",
    "        loss = 0\n",
    "        not_eosed_before = torch.ones(receiver_output.size(0)).to(\n",
    "            receiver_output.device\n",
    "        )\n",
    "        expected_length = 0.0\n",
    "\n",
    "        aux_info = {}\n",
    "        z = 0.0\n",
    "        for step in range(receiver_output.size(1)):\n",
    "            step_loss, step_aux = self.loss(\n",
    "                sender_input,\n",
    "                message[:, step, ...],\n",
    "                receiver_input,\n",
    "                receiver_output[:, step, ...],\n",
    "                labels,\n",
    "                aux_input,\n",
    "            )\n",
    "            eos_mask = message[:, step, 0]  # always eos == 0\n",
    "\n",
    "            add_mask = eos_mask * not_eosed_before\n",
    "            z += add_mask\n",
    "            loss += step_loss * add_mask + self.length_cost * (1.0 + step) * add_mask\n",
    "            expected_length += add_mask.detach() * (1.0 + step)\n",
    "\n",
    "            for name, value in step_aux.items():\n",
    "                aux_info[name] = value * add_mask + aux_info.get(name, 0.0)\n",
    "\n",
    "            not_eosed_before = not_eosed_before * (1.0 - eos_mask)\n",
    "\n",
    "        # the remainder of the probability mass\n",
    "        loss += (\n",
    "            step_loss * not_eosed_before\n",
    "            + self.length_cost * (step + 1.0) * not_eosed_before\n",
    "        )\n",
    "        expected_length += (step + 1) * not_eosed_before\n",
    "\n",
    "        z += not_eosed_before\n",
    "        assert z.allclose(\n",
    "            torch.ones_like(z)\n",
    "        ), f\"lost probability mass, {z.min()}, {z.max()}\"\n",
    "\n",
    "        for name, value in step_aux.items():\n",
    "            aux_info[name] = value * not_eosed_before + aux_info.get(name, 0.0)\n",
    "\n",
    "        aux_info[\"length\"] = expected_length\n",
    "\n",
    "        logging_strategy = (\n",
    "            self.train_logging_strategy if self.training else self.test_logging_strategy\n",
    "        )\n",
    "        interaction = logging_strategy.filtered_interaction(\n",
    "            sender_input=torch.zeros(sender_input.num_nodes), # MODIFIED\n",
    "            receiver_input=torch.zeros(sender_input.num_nodes), # MODIFIED\n",
    "            labels=labels,\n",
    "            aux_input=aux_input,\n",
    "            receiver_output=receiver_output.detach(),\n",
    "            message=message.detach(),\n",
    "            message_length=expected_length.detach(),\n",
    "            aux=aux_info,\n",
    "        )\n",
    "\n",
    "        return loss.mean(), interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Interaction(sender_input=tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), receiver_input=tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), labels=tensor([0, 1, 0, 0, 0, 0, 0, 0, 0]), aux_input=None, message=tensor([[[3.2741e-03, 5.3805e-03, 5.6546e-04, 1.4919e-02, 1.2929e-02,\n",
      "          8.1527e-02, 4.0610e-01, 1.3966e-04, 9.5604e-03, 2.7534e-02,\n",
      "          1.9643e-02, 1.5255e-04, 1.5031e-04, 1.1153e-03, 6.6448e-02,\n",
      "          4.3851e-03, 8.4110e-04, 2.4364e-04, 6.6930e-02, 2.7816e-01],\n",
      "         [2.4063e-03, 2.7710e-03, 2.4723e-04, 8.2089e-01, 3.8277e-03,\n",
      "          1.8013e-03, 8.5198e-02, 8.3164e-03, 6.7180e-03, 1.0799e-02,\n",
      "          1.7178e-02, 8.2034e-04, 1.3892e-04, 1.0117e-03, 6.8539e-03,\n",
      "          2.0015e-03, 3.8317e-04, 9.2605e-04, 1.8848e-02, 8.8655e-03],\n",
      "         [8.0806e-03, 1.2795e-02, 3.2145e-03, 1.7831e-02, 2.6261e-02,\n",
      "          1.5558e-01, 5.2083e-02, 1.8758e-02, 1.5623e-02, 1.4591e-02,\n",
      "          8.9768e-03, 5.2383e-02, 1.0774e-02, 4.9124e-02, 2.7331e-01,\n",
      "          8.1389e-03, 1.4472e-02, 1.7716e-02, 4.9674e-02, 1.9062e-01],\n",
      "         [3.4521e-02, 4.4958e-02, 7.7583e-03, 8.3463e-03, 5.7139e-03,\n",
      "          1.6413e-02, 3.8203e-02, 2.0284e-03, 1.1873e-02, 5.1836e-02,\n",
      "          9.6384e-03, 1.5384e-03, 3.1908e-03, 4.4842e-01, 6.9069e-02,\n",
      "          1.9362e-02, 6.2042e-03, 3.4436e-02, 4.4953e-02, 1.4154e-01],\n",
      "         [7.2570e-03, 4.8944e-03, 2.2179e-03, 6.8841e-03, 5.6772e-03,\n",
      "          2.9260e-03, 2.4465e-02, 2.4865e-02, 6.2376e-03, 3.6747e-01,\n",
      "          2.5380e-03, 9.9602e-03, 1.7743e-01, 3.4670e-02, 2.7251e-02,\n",
      "          2.7725e-01, 2.2622e-03, 7.1078e-03, 1.8493e-03, 6.7880e-03],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]), receiver_output=tensor([[[0.0259, 0.0259],\n",
      "         [0.0200, 0.0200],\n",
      "         [0.0116, 0.0116],\n",
      "         [0.0109, 0.0109],\n",
      "         [0.0171, 0.0171],\n",
      "         [0.0229, 0.0229]],\n",
      "\n",
      "        [[0.0261, 0.0261],\n",
      "         [0.0201, 0.0201],\n",
      "         [0.0117, 0.0117],\n",
      "         [0.0110, 0.0110],\n",
      "         [0.0172, 0.0172],\n",
      "         [0.0230, 0.0230]],\n",
      "\n",
      "        [[0.1575, 0.1575],\n",
      "         [0.1597, 0.1597],\n",
      "         [0.1634, 0.1634],\n",
      "         [0.1628, 0.1628],\n",
      "         [0.1612, 0.1612],\n",
      "         [0.1562, 0.1562]],\n",
      "\n",
      "        [[0.1629, 0.1629],\n",
      "         [0.1675, 0.1675],\n",
      "         [0.1728, 0.1728],\n",
      "         [0.1722, 0.1722],\n",
      "         [0.1707, 0.1707],\n",
      "         [0.1664, 0.1664]],\n",
      "\n",
      "        [[0.1446, 0.1446],\n",
      "         [0.1510, 0.1510],\n",
      "         [0.1634, 0.1634],\n",
      "         [0.1678, 0.1678],\n",
      "         [0.1515, 0.1515],\n",
      "         [0.1473, 0.1473]],\n",
      "\n",
      "        [[0.1538, 0.1538],\n",
      "         [0.1604, 0.1604],\n",
      "         [0.1741, 0.1741],\n",
      "         [0.1780, 0.1780],\n",
      "         [0.1614, 0.1614],\n",
      "         [0.1550, 0.1550]],\n",
      "\n",
      "        [[0.1785, 0.1785],\n",
      "         [0.1884, 0.1884],\n",
      "         [0.1981, 0.1981],\n",
      "         [0.1967, 0.1967],\n",
      "         [0.1960, 0.1960],\n",
      "         [0.1924, 0.1924]],\n",
      "\n",
      "        [[0.0851, 0.0851],\n",
      "         [0.0780, 0.0780],\n",
      "         [0.0635, 0.0635],\n",
      "         [0.0611, 0.0611],\n",
      "         [0.0750, 0.0750],\n",
      "         [0.0826, 0.0826]],\n",
      "\n",
      "        [[0.0656, 0.0656],\n",
      "         [0.0549, 0.0549],\n",
      "         [0.0413, 0.0413],\n",
      "         [0.0395, 0.0395],\n",
      "         [0.0497, 0.0497],\n",
      "         [0.0541, 0.0541]]]), message_length=tensor([5.8749, 5.8749, 5.8749, 5.8749, 5.8749, 5.8749, 5.8749, 5.8749, 5.8749]), aux={'acc': tensor([0.8889, 0.8889, 0.8889, 0.8889, 0.8889, 0.8889, 0.8889, 0.8889, 0.8889],\n",
      "       grad_fn=<AddBackward0>), 'length': tensor([5.8749, 5.8749, 5.8749, 5.8749, 5.8749, 5.8749, 5.8749, 5.8749, 5.8749],\n",
      "       grad_fn=<AddBackward0>)})\n"
     ]
    }
   ],
   "source": [
    "game = CustomSenderReceiverRnnGS(sender_wrapped, receiver_wrapped, loss_nll)\n",
    "\n",
    "loss, interaction = game(sender_input=graph, labels=graph.labels, receiver_input=graph, aux_input=None)\n",
    "print(\"====================================\")\n",
    "print(interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I have modified the Batch, Trainer and Game classes from EGG which is not ideal. However I keep getting stuck when I want to apply Phong's method. This is mainly because I can't get my agents to handle batches. They are disigned to do one graph at a time since I calculate the message and therefore the labels per graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": -0.15072019398212433, \"acc\": 0.8541667461395264, \"length\": 5.5017266273498535, \"mode\": \"train\", \"epoch\": 1}\n",
      "{\"loss\": -0.13650795817375183, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 1}\n",
      "{\"loss\": -0.14927984774112701, \"acc\": 0.8564102053642273, \"length\": 5.320054531097412, \"mode\": \"train\", \"epoch\": 2}\n",
      "{\"loss\": -0.13650791347026825, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 2}\n",
      "{\"loss\": -0.13827162981033325, \"acc\": 0.8413461446762085, \"length\": 5.404200553894043, \"mode\": \"train\", \"epoch\": 3}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 3}\n",
      "{\"loss\": -0.1443415880203247, \"acc\": 0.8557214140892029, \"length\": 5.441940784454346, \"mode\": \"train\", \"epoch\": 4}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 4}\n",
      "{\"loss\": -0.15709877014160156, \"acc\": 0.8709677457809448, \"length\": 5.48160982131958, \"mode\": \"train\", \"epoch\": 5}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 5}\n",
      "{\"loss\": -0.1478395313024521, \"acc\": 0.8358975052833557, \"length\": 5.268789291381836, \"mode\": \"train\", \"epoch\": 6}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 6}\n",
      "{\"loss\": -0.16347736120224, \"acc\": 0.8579545617103577, \"length\": 5.1108574867248535, \"mode\": \"train\", \"epoch\": 7}\n",
      "{\"loss\": -0.13650791347026825, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 7}\n",
      "{\"loss\": -0.154115229845047, \"acc\": 0.8571428656578064, \"length\": 5.263200283050537, \"mode\": \"train\", \"epoch\": 8}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 8}\n",
      "{\"loss\": -0.15751029551029205, \"acc\": 0.8579235076904297, \"length\": 5.136253356933594, \"mode\": \"train\", \"epoch\": 9}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 9}\n",
      "{\"loss\": -0.14866255223751068, \"acc\": 0.8564102649688721, \"length\": 5.270835876464844, \"mode\": \"train\", \"epoch\": 10}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 10}\n",
      "{\"loss\": -0.14639918506145477, \"acc\": 0.8550000190734863, \"length\": 5.486487865447998, \"mode\": \"train\", \"epoch\": 11}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 11}\n",
      "{\"loss\": -0.14763376116752625, \"acc\": 0.8375635147094727, \"length\": 5.459618091583252, \"mode\": \"train\", \"epoch\": 12}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 12}\n",
      "{\"loss\": -0.1532921940088272, \"acc\": 0.8571429252624512, \"length\": 5.492609977722168, \"mode\": \"train\", \"epoch\": 13}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 13}\n",
      "{\"loss\": -0.14228396117687225, \"acc\": 0.8599033355712891, \"length\": 5.3694539070129395, \"mode\": \"train\", \"epoch\": 14}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 14}\n",
      "{\"loss\": -0.15925925970077515, \"acc\": 0.8524590134620667, \"length\": 5.419050693511963, \"mode\": \"train\", \"epoch\": 15}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 15}\n",
      "{\"loss\": -0.14845679700374603, \"acc\": 0.8410256505012512, \"length\": 5.252631187438965, \"mode\": \"train\", \"epoch\": 16}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 16}\n",
      "{\"loss\": -0.15761318802833557, \"acc\": 0.8494623899459839, \"length\": 5.421531677246094, \"mode\": \"train\", \"epoch\": 17}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 17}\n",
      "{\"loss\": -0.15133748948574066, \"acc\": 0.859375, \"length\": 5.212767124176025, \"mode\": \"train\", \"epoch\": 18}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 18}\n",
      "{\"loss\": -0.14917698502540588, \"acc\": 0.8564103245735168, \"length\": 5.492829322814941, \"mode\": \"train\", \"epoch\": 19}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 19}\n",
      "{\"loss\": -0.13117283582687378, \"acc\": 0.8341014385223389, \"length\": 5.512176990509033, \"mode\": \"train\", \"epoch\": 20}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 20}\n",
      "{\"loss\": -0.15174899995326996, \"acc\": 0.8324607610702515, \"length\": 5.462879657745361, \"mode\": \"train\", \"epoch\": 21}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 21}\n",
      "{\"loss\": -0.15565843880176544, \"acc\": 0.8502673506736755, \"length\": 5.423575401306152, \"mode\": \"train\", \"epoch\": 22}\n",
      "{\"loss\": -0.13650792837142944, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 22}\n",
      "{\"loss\": -0.16244857013225555, \"acc\": 0.8603351712226868, \"length\": 5.094472885131836, \"mode\": \"train\", \"epoch\": 23}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 23}\n",
      "{\"loss\": -0.15267492830753326, \"acc\": 0.8571428060531616, \"length\": 5.5727763175964355, \"mode\": \"train\", \"epoch\": 24}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 24}\n",
      "{\"loss\": -0.1424897313117981, \"acc\": 0.8522167205810547, \"length\": 5.381600379943848, \"mode\": \"train\", \"epoch\": 25}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 25}\n",
      "{\"loss\": -0.14465022087097168, \"acc\": 0.8663365840911865, \"length\": 5.396570682525635, \"mode\": \"train\", \"epoch\": 26}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 26}\n",
      "{\"loss\": -0.1478395313024521, \"acc\": 0.8673469424247742, \"length\": 5.507619380950928, \"mode\": \"train\", \"epoch\": 27}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 27}\n",
      "{\"loss\": -0.15493829548358917, \"acc\": 0.8395721912384033, \"length\": 5.351287841796875, \"mode\": \"train\", \"epoch\": 28}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 28}\n",
      "{\"loss\": -0.14454734325408936, \"acc\": 0.8542713522911072, \"length\": 5.644139289855957, \"mode\": \"train\", \"epoch\": 29}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 29}\n",
      "{\"loss\": -0.1518518626689911, \"acc\": 0.8429320454597473, \"length\": 5.5094780921936035, \"mode\": \"train\", \"epoch\": 30}\n",
      "{\"loss\": -0.13650794327259064, \"acc\": 0.8545454740524292, \"length\": 6.0, \"mode\": \"test\", \"epoch\": 30}\n"
     ]
    }
   ],
   "source": [
    "opts = core.init(params=['--random_seed=7', \n",
    "                         '--lr=1e-3',   \n",
    "                         f'--batch_size={options.batch_size}',\n",
    "                         '--optimizer=adam'])\n",
    "\n",
    "optimizer = torch.optim.Adam(game.parameters())\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    game=game, \n",
    "    optimizer=optimizer, \n",
    "    train_data=train_loader,\n",
    "    validation_data=test_loader, \n",
    "    callbacks=[core.ConsoleLogger(as_json=True, print_train_loss=True)]\n",
    ")\n",
    "\n",
    "trainer.train(n_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
